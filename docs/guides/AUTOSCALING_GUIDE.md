# Kubernetes Autoscaling Guide

Este guia explica como funciona o autoscaling automÃ¡tico dos pods baseado em carga (CPU e memÃ³ria) no cluster Kubernetes.

---

## ğŸ¯ Overview

O sistema estÃ¡ configurado com **HorizontalPodAutoscaler (HPA)** que automaticamente ajusta o nÃºmero de rÃ©plicas dos pods baseado em mÃ©tricas de CPU e memÃ³ria.

### CaracterÃ­sticas

- âœ… **Autoscaling baseado em CPU** - Target: 70% de utilizaÃ§Ã£o
- âœ… **Autoscaling baseado em MemÃ³ria** - Target: 80% de utilizaÃ§Ã£o
- âœ… **Escala automÃ¡tica**: 2 (mÃ­nimo) â†’ 10 (mÃ¡ximo) rÃ©plicas
- âœ… **Scale-up rÃ¡pido**: AtÃ© 100% em 30s ou 4 pods
- âœ… **Scale-down conservador**: MÃ¡ximo 50% em 60s apÃ³s 5min de estabilidade

---

## ğŸ“Š ConfiguraÃ§Ã£o Atual

### Ticket Service HPA

```yaml
Min Replicas: 2
Max Replicas: 10
Target CPU: 70%
Target Memory: 80%
```

### Vacancy Service HPA

```yaml
Min Replicas: 2
Max Replicas: 10
Target CPU: 70%
Target Memory: 80%
```

### PolÃ­ticas de Scaling

**Scale Up (Aumentar pods)**:
- âš¡ **Imediato** - Sem janela de estabilizaÃ§Ã£o
- ğŸ“ˆ **Agressivo** - AtÃ© 100% de aumento a cada 30s
- ğŸš€ **Ou** - Adiciona atÃ© 4 pods a cada 30s
- ğŸ¯ **Escolhe o maior** entre os dois valores

**Scale Down (Reduzir pods)**:
- â³ **Conservador** - Aguarda 5 minutos de estabilidade
- ğŸ“‰ **Gradual** - MÃ¡ximo 50% de reduÃ§Ã£o a cada 60s
- ğŸŒ **Ou** - Remove no mÃ¡ximo 2 pods a cada 60s
- ğŸ¯ **Escolhe o menor** entre os dois valores

---

## ğŸš€ Como Usar

### Ver Status do HPA

```bash
# Via Makefile
make hpa-status

# Direto com kubectl
kubectl get hpa -n ticket-system
```

**Output**:
```
NAME                  REFERENCE                    TARGETS                        MINPODS   MAXPODS   REPLICAS
ticket-service-hpa    Deployment/ticket-service    cpu: 4%/70%, memory: 77%/80%   2         10        2
vacancy-service-hpa   Deployment/vacancy-service   cpu: 3%/70%, memory: 74%/80%   2         10        2
```

### Monitorar Scaling em Tempo Real

```bash
# Via Makefile (requer 'watch' instalado)
make watch-hpa

# Ou manualmente
watch -n 2 'kubectl get hpa -n ticket-system && echo "" && kubectl get pods -n ticket-system'
```

### Ver MÃ©tricas dos Pods

```bash
kubectl top pods -n ticket-system
```

**Output**:
```
NAME                              CPU(cores)   MEMORY(bytes)
ticket-service-xxx                4m           101Mi
ticket-service-yyy                4m           96Mi
vacancy-service-xxx               3m           97Mi
vacancy-service-yyy               4m           92Mi
```

---

## ğŸ§ª Testar Autoscaling

### Teste RÃ¡pido com Hey

```bash
# Gerar carga por 60 segundos com 50 conexÃµes concorrentes
hey -z 60s -c 50 -m POST \
  -H "Content-Type: application/json" \
  -d '{"qty":1}' \
  http://ticket.127.0.0.1.nip.io/api/v1/purchase

# Em outro terminal, monitorar
make watch-hpa
```

### Teste Completo com K6

```bash
# Teste de 17 minutos que escala de 0 â†’ 150 VUs
k6 run ticket-system-k6-autoscaling.js

# Monitorar em outro terminal
kubectl get hpa -n ticket-system -w
```

**Fases do teste K6**:
1. **0-1min**: Warm-up com 10 VUs (baseline)
2. **1-3min**: Aumenta para 50 VUs (trigger scaling)
3. **3-6min**: Aumenta para 100 VUs (scale to ~6-8 pods)
4. **6-8min**: Peak de 150 VUs (scale to max ~10 pods)
5. **8-11min**: Sustenta 150 VUs (verificar estabilidade)
6. **11-17min**: Reduz gradualmente (observe scale down)

---

## ğŸ“ˆ Comportamento Observado

### Teste Real - 60s com 50 conexÃµes

**InÃ­cio** (antes da carga):
```
ticket-service:  2 pods, CPU 3%, Memory 77%
vacancy-service: 2 pods, CPU 3%, Memory 74%
```

**Durante a carga** (apÃ³s 30s):
```
ticket-service:  10 pods, CPU 184%, Memory 80%  â† Escalou para mÃ¡ximo!
vacancy-service: 8 pods,  CPU 149%, Memory 76%  â† Escalou para 8!
```

**Resultados**:
- ğŸ“Š **63,464 requests** processados em 60s
- ğŸš€ **1,056 req/s** de throughput
- âœ… **0% de erros** - 100% success rate
- âš¡ **P95 latency**: 219ms (aceitÃ¡vel durante scaling)
- ğŸ“ˆ **Scaling**: 2 â†’ 10 pods (ticket) e 2 â†’ 8 pods (vacancy)

**ApÃ³s a carga** (scale down):
- â³ Aguarda 5 minutos de estabilidade
- ğŸ“‰ Reduz gradualmente 50% a cada 60s
- ğŸ¯ Retorna para 2 pods em ~10 minutos

---

## ğŸ” Entendendo as MÃ©tricas

### CPU Utilization

```
cpu: 184%/70%
     ^^^  ^^
     |    |
     |    â””â”€ Target (70%)
     â””â”€â”€â”€â”€â”€â”€ Atual (184% = muito acima do target)
```

**InterpretaÃ§Ã£o**:
- **< 70%**: Dentro do target, sem escalar
- **> 70%**: Acima do target, **SCALE UP** necessÃ¡rio
- **> 100%**: Pods sobrecarregados, scale up urgente

### Memory Utilization

```
memory: 85%/80%
        ^^  ^^
        |   |
        |   â””â”€ Target (80%)
        â””â”€â”€â”€â”€â”€ Atual (85% = acima do target)
```

**InterpretaÃ§Ã£o**:
- **< 80%**: Dentro do target
- **> 80%**: Acima do target, **SCALE UP** necessÃ¡rio
- **> 90%**: Risco de OOM (Out of Memory)

---

## ğŸ¯ Quando o HPA Escala

### Scale Up (Adiciona Pods)

O HPA adiciona pods quando:

1. **CPU ou Memory acima do target** por ~15-30 segundos
2. **Exemplo**: CPU atual 184% > 70% target
3. **CÃ¡lculo**: Desired = Current Ã— (Current / Target)
   - Current: 2 pods com 184% CPU
   - Desired: 2 Ã— (184 / 70) = 5.26 â†’ arredonda para 6 pods
   - PolÃ­ticas: Pode adicionar atÃ© 4 pods a cada 30s
   - Resultado: Escala para 6 pods (de 2)

4. **PrÃ³ximo ciclo** (30s depois):
   - Se ainda acima de 70%, adiciona mais pods
   - Continua atÃ© atingir maxReplicas (10) ou ficar abaixo do target

### Scale Down (Remove Pods)

O HPA remove pods quando:

1. **CPU e Memory abaixo do target** por **5 minutos** (stabilizationWindow)
2. **Exemplo**: CPU atual 20% < 70% target
3. **Aguarda**: 5 minutos de estabilidade para evitar flapping
4. **CÃ¡lculo**: Similar ao scale up, mas com polÃ­ticas mais conservadoras
5. **Reduz**: MÃ¡ximo 50% ou 2 pods a cada 60s
6. **Continua**: AtÃ© atingir minReplicas (2)

---

## ğŸ› ï¸ Troubleshooting

### HPA mostra "<unknown>" nas mÃ©tricas

**Problema**:
```
TARGETS: cpu: <unknown>/70%, memory: <unknown>/80%
```

**Causas**:
1. Metrics-server nÃ£o estÃ¡ rodando
2. Metrics-server ainda coletando dados (aguarde 30-60s)
3. Pods sem resource requests definidos

**SoluÃ§Ã£o**:
```bash
# Verificar metrics-server
kubectl get pods -n kube-system | grep metrics

# Verificar se estÃ¡ coletando mÃ©tricas
kubectl top nodes
kubectl top pods -n ticket-system

# Se nÃ£o funcionar, reinstalar
kubectl delete deployment metrics-server -n kube-system
# Executar make install-metrics-server
```

### HPA nÃ£o estÃ¡ escalando

**Problema**: Carga alta mas pods nÃ£o aumentam

**Verificar**:
```bash
# 1. Ver eventos do HPA
kubectl describe hpa -n ticket-system ticket-service-hpa

# 2. Ver mÃ©tricas atuais
kubectl top pods -n ticket-system

# 3. Ver resource requests/limits
kubectl describe pod -n ticket-system <pod-name> | grep -A5 Requests
```

**Causas comuns**:
1. CPU/Memory nÃ£o ultrapassaram o target
2. JÃ¡ estÃ¡ no maxReplicas
3. Metrics-server com problemas
4. Requests nÃ£o definidos nos pods

### Pods escalando demais (flapping)

**Problema**: Pods ficam aumentando/diminuindo constantemente

**Causa**: Janela de estabilizaÃ§Ã£o muito curta

**SoluÃ§Ã£o**: Ajustar `stabilizationWindowSeconds` no HPA:
```yaml
behavior:
  scaleDown:
    stabilizationWindowSeconds: 600  # Aumentar para 10min
```

---

## ğŸ“Š Arquivos Relacionados

| Arquivo | DescriÃ§Ã£o |
|---------|-----------|
| `k8s/vacancy-hpa.yaml` | HPA para vacancy service |
| `k8s/ticket-hpa.yaml` | HPA para ticket service |
| `k8s/vacancy-deployment-registry.yaml` | Deployment com resource requests |
| `k8s/ticket-deployment-registry.yaml` | Deployment com resource requests |
| `ticket-system-k6-autoscaling.js` | Teste K6 para autoscaling |

---

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Alterar Targets de CPU/Memory

Editar o HPA:
```bash
kubectl edit hpa ticket-service-hpa -n ticket-system
```

Mudar valores:
```yaml
metrics:
- type: Resource
  resource:
    name: cpu
    target:
      type: Utilization
      averageUtilization: 70  # Mudar aqui (50-80 recomendado)
```

### Alterar Min/Max Replicas

```bash
kubectl patch hpa ticket-service-hpa -n ticket-system -p '{"spec":{"minReplicas":3,"maxReplicas":20}}'
```

### Alterar Comportamento de Scaling

Editar polÃ­ticas em `k8s/ticket-hpa.yaml`:
```yaml
behavior:
  scaleUp:
    stabilizationWindowSeconds: 0     # Imediato
    policies:
    - type: Percent
      value: 200                      # Dobrar a cada ciclo
      periodSeconds: 15                # A cada 15s
```

---

## ğŸ“ˆ MÃ©tricas Customizadas (Futuro)

AlÃ©m de CPU e Memory, vocÃª pode escalar baseado em:

### RequisiÃ§Ãµes por Segundo (RPS)

```yaml
metrics:
- type: Pods
  pods:
    metric:
      name: http_requests_per_second
    target:
      type: AverageValue
      averageValue: "100"  # 100 req/s por pod
```

### LatÃªncia

```yaml
metrics:
- type: Pods
  pods:
    metric:
      name: http_request_duration_seconds
    target:
      type: AverageValue
      averageValue: "0.1"  # 100ms
```

**Requer**: Prometheus + Custom Metrics API

---

## ğŸ“ Best Practices

### 1. Sempre Defina Resource Requests

```yaml
resources:
  requests:
    memory: "128Mi"  # OBRIGATÃ“RIO para HPA
    cpu: "100m"      # OBRIGATÃ“RIO para HPA
  limits:
    memory: "512Mi"
    cpu: "500m"
```

### 2. Teste Antes de ProduÃ§Ã£o

```bash
# Testar com carga sintÃ©tica
make load-test

# Monitorar comportamento
make watch-hpa
```

### 3. Configure Alertas

- âš ï¸ Alerta quando pods = maxReplicas (capacidade mÃ¡xima)
- âš ï¸ Alerta quando CPU > 90% por 5min (insuficiente)
- âš ï¸ Alerta quando HPA nÃ£o consegue escalar

### 4. Ajuste Conservadoramente

- Comece com targets altos (70-80%)
- Observe por dias/semanas
- Ajuste baseado em dados reais
- Evite over-provisioning

### 5. Combine com Cluster Autoscaler

Para produÃ§Ã£o, combine HPA (pods) com Cluster Autoscaler (nodes):
- HPA: Aumenta pods atÃ© maxReplicas
- CA: Se nodes sem capacidade, adiciona nodes
- Resultado: Escalabilidade ilimitada (atÃ© limites de cloud)

---

## ğŸ“Š Monitoramento em ProduÃ§Ã£o

### MÃ©tricas para Observar

1. **HPA Metrics**:
   ```bash
   kubectl get hpa -n ticket-system -o yaml
   ```

2. **Pod Scaling Events**:
   ```bash
   kubectl get events -n ticket-system --sort-by='.lastTimestamp'
   ```

3. **Resource Utilization**:
   ```bash
   kubectl top pods -n ticket-system --containers
   ```

### Grafana Dashboards

MÃ©tricas Ãºteis para Prometheus/Grafana:
- `kube_hpa_status_current_replicas`
- `kube_hpa_status_desired_replicas`
- `kube_hpa_spec_max_replicas`
- `kube_pod_container_resource_requests_cpu_cores`
- `kube_pod_container_resource_limits_cpu_cores`

---

## ğŸ¯ Comandos RÃ¡pidos

```bash
# Ver status
make hpa-status

# Monitorar em tempo real
make watch-hpa

# Descrever HPA (ver eventos)
kubectl describe hpa ticket-service-hpa -n ticket-system

# Ver Ãºltimos eventos de scaling
kubectl get events -n ticket-system | grep -i scale

# ForÃ§ar scaling manual (teste)
kubectl scale deployment ticket-service -n ticket-system --replicas=5

# Deletar HPA (volta para rÃ©plicas fixas)
kubectl delete hpa -n ticket-system --all
```

---

## ğŸ”§ Makefile Commands

```bash
make deploy-hpa      # Deploy HPAs
make hpa-status      # Ver status e mÃ©tricas
make watch-hpa       # Monitorar em tempo real
```

---

## ğŸ“ Exemplo Completo

### CenÃ¡rio: Black Friday

**PreparaÃ§Ã£o**:
```bash
# 1. Verificar HPAs configurados
make hpa-status

# 2. Aumentar maxReplicas para demanda
kubectl patch hpa ticket-service-hpa -n ticket-system \
  -p '{"spec":{"maxReplicas":20}}'
```

**Durante o evento**:
```bash
# Monitorar em tempo real
make watch-hpa
```

**Comportamento esperado**:
- **08:00**: 2 pods (baseline)
- **09:00**: InÃ­cio das vendas, CPU sobe
- **09:02**: HPA escala para 6 pods
- **09:05**: HPA escala para 10 pods
- **09:10**: HPA escala para 15 pods (pico)
- **12:00**: Vendas caem, CPU baixa
- **12:05**: HPA comeÃ§a scale down
- **12:15**: Retorna para 4-6 pods
- **18:00**: Retorna para 2 pods (baseline)

---

## âœ… ValidaÃ§Ã£o

Sistema com autoscaling estÃ¡ OK quando:

- âœ… `make hpa-status` mostra mÃ©tricas vÃ¡lidas (nÃ£o `<unknown>`)
- âœ… TARGETS mostram CPU e Memory com valores percentuais
- âœ… REPLICAS estÃ¡ entre MINPODS e MAXPODS
- âœ… Sob carga, REPLICAS aumenta automaticamente
- âœ… Sem carga, REPLICAS volta para MINPODS

---

**VersÃ£o**: 1.0.0
**Ãšltima atualizaÃ§Ã£o**: 2025-11-02
**Testado**: âœ… Funcionando perfeitamente (2 â†’ 10 pods em 60s)
